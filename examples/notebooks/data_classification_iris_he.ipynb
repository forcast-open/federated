{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stock-sound",
   "metadata": {},
   "source": [
    "This example contains the necessary bits of code to run the federated training with homomorphic encryption (he)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "medium-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import jsonpickle as jpk\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "# Federated imports\n",
    "import forcast_federated_learning as ffl\n",
    "\n",
    "# Parameters\n",
    "num_clients        = 10\n",
    "com_rounds         = 40\n",
    "seed               = 0\n",
    "batch_size         = 1\n",
    "noise_multiplier   = 0.3\n",
    "max_grad_norm      = 0.5\n",
    "\n",
    "# Metrics\n",
    "df_metrics = pd.DataFrame(dict(zip(['round', 'rmse', 'r2_score', 'epsilon', 'delta'], [int,[],[],[],[]])))\n",
    "\n",
    "# Load local train data\n",
    "X, y, df_data, target_names = ffl.datasets.load_scikit_iris()\n",
    "\n",
    "# Split the database in train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=seed)  \n",
    "\n",
    "# Create custom pytorch datasers for train and testing\n",
    "traindata = ffl.datasets.StructuredDataset(X_train, y_train, categorical=True)\n",
    "testdata  = ffl.datasets.StructuredDataset(X_test, y_test, categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-separation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train data and use only a fraction\n",
    "traindata_split = ffl.data.random_split(traindata, num_clients=num_clients, seed=seed)\n",
    "\n",
    "# Get data loader\n",
    "train_loaders = [ffl.utils.DataLoader(traindata, batch_size=batch_size, shuffle=True, seed=seed)   for traindata in traindata_split]\n",
    "test_loader  = ffl.utils.DataLoader(testdata, batch_size=len(testdata), shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "danish-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train params\n",
    "delta              = 10**-np.ceil(np.log10(len(traindata))) # delta < 1/len(dataset)\n",
    "security_params    = {'noise_multiplier': noise_multiplier, 'max_grad_norm': max_grad_norm, 'batch_size': batch_size, 'sample_size': len(traindata), 'target_delta': delta, 'secure_rng': True} \n",
    "optimizer_params   = {'lr': 0.01}\n",
    "train_params       = {'epochs': 4}\n",
    "\n",
    "local_models       = []\n",
    "for _ in range(num_clients):\n",
    "    # Create federated model based on a pytorch model\n",
    "    num_features, num_classes  = 4, 3\n",
    "    model                      = ffl.models.NN(input_dim=num_features, output_dim=num_classes) # pytorch model\n",
    "    loss_fn                    = nn.CrossEntropyLoss() # classification\n",
    "    local_model                = ffl.LocalModel(model, model_type = 'nn', loss_fn=loss_fn, train_params=train_params)\n",
    "    local_model.optimizer      = ffl.optim.Adam(local_model.parameters(), **optimizer_params)\n",
    "    local_model.privacy_engine = ffl.security.PrivacyEngine(local_model, **security_params)\n",
    "    local_model.privacy_engine.attach(local_model.optimizer)\n",
    "    \n",
    "    local_models.append(local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "coral-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "model           = local_model.model # pytorch model\n",
    "fed_model       = ffl.FederatedModel(model, model_type='nn')\n",
    "public_context, secret_key = ffl.encryption.get_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-career",
   "metadata": {},
   "source": [
    "As a coment in practice, when deploying the public_context object need to be serialized to be shared with the clients with `context = public_context.serialize()`, and then each client needs to load it onto a python object with `context = ffl.encryption.load_context(context)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "artistic-wiring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e4855a935aa41a883327f161bf242e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=40.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 32.00 - Privacy spent: (ε = 13.59, δ = 0.01)\n",
      "Test accuracy: 32.00 - Privacy spent: (ε = 16.83, δ = 0.01)\n",
      "Test accuracy: 32.00 - Privacy spent: (ε = 19.49, δ = 0.01)\n",
      "Test accuracy: 32.00 - Privacy spent: (ε = 22.14, δ = 0.01)\n",
      "Test accuracy: 42.00 - Privacy spent: (ε = 23.95, δ = 0.01)\n",
      "Test accuracy: 64.00 - Privacy spent: (ε = 25.68, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 27.40, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 29.12, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 30.84, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 32.56, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 34.28, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 36.00, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 37.72, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 39.44, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 40.66, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 41.83, δ = 0.01)\n",
      "Test accuracy: 62.00 - Privacy spent: (ε = 43.01, δ = 0.01)\n",
      "Test accuracy: 66.00 - Privacy spent: (ε = 44.18, δ = 0.01)\n",
      "Test accuracy: 74.00 - Privacy spent: (ε = 45.36, δ = 0.01)\n",
      "Test accuracy: 72.00 - Privacy spent: (ε = 46.53, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 47.71, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 48.88, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 50.06, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 51.23, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 52.41, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 53.58, δ = 0.01)\n",
      "Test accuracy: 82.00 - Privacy spent: (ε = 54.76, δ = 0.01)\n",
      "Test accuracy: 90.00 - Privacy spent: (ε = 55.94, δ = 0.01)\n",
      "Test accuracy: 80.00 - Privacy spent: (ε = 57.11, δ = 0.01)\n",
      "Test accuracy: 90.00 - Privacy spent: (ε = 58.29, δ = 0.01)\n",
      "Test accuracy: 94.00 - Privacy spent: (ε = 59.46, δ = 0.01)\n",
      "Test accuracy: 96.00 - Privacy spent: (ε = 60.64, δ = 0.01)\n",
      "Test accuracy: 96.00 - Privacy spent: (ε = 61.81, δ = 0.01)\n",
      "Test accuracy: 94.00 - Privacy spent: (ε = 62.99, δ = 0.01)\n",
      "Test accuracy: 96.00 - Privacy spent: (ε = 64.16, δ = 0.01)\n",
      "Test accuracy: 98.00 - Privacy spent: (ε = 65.34, δ = 0.01)\n",
      "Test accuracy: 98.00 - Privacy spent: (ε = 66.51, δ = 0.01)\n",
      "Test accuracy: 98.00 - Privacy spent: (ε = 67.69, δ = 0.01)\n",
      "Test accuracy: 98.00 - Privacy spent: (ε = 68.86, δ = 0.01)\n",
      "Test accuracy: 98.00 - Privacy spent: (ε = 70.04, δ = 0.01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for com_round in tqdm(range(com_rounds)):\n",
    "    for local_model, train_loader in zip(local_models, train_loaders):\n",
    "        local_model.step(train_loader)\n",
    "    \n",
    "    client_weights = []\n",
    "    for local_model in local_models:\n",
    "        state_dict      = local_model.state_dict()\n",
    "        enc_state_dict  = ffl.encryption.EncStateDict(state_dict)\n",
    "        enc_state_dict  = enc_state_dict.encrypt(public_context)\n",
    "        client_weights.append(enc_state_dict)\n",
    "    client_lens    = [len(traindata) for traindata in traindata_split]\n",
    "    \n",
    "    ## Server aggregate\n",
    "    fed_model.server_agregate(client_weights, client_lens, secret_key=secret_key)\n",
    "    weights = fed_model.state_dict()\n",
    "    \n",
    "    for local_model in local_models:\n",
    "        local_model.load_state_dict(weights)\n",
    "    \n",
    "    acc, _ = local_model.test(test_loader)\n",
    "    if local_model.privacy_engine: # privacy spent\n",
    "        epsilon, best_alpha = local_model.privacy_engine.get_privacy_spent(delta)\n",
    "        print(f'Test accuracy: {acc:.2f} - Privacy spent: (ε = {epsilon:.2f}, δ = {delta:.2f})')\n",
    "    else: \n",
    "        print(f'Test accuracy: {acc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-capacity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-pitch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
